{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pickle, os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import requests\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "import torch\n",
    "import gc, sys, psutil\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./videodatainfo_2017_ustc.json', 'r') as f:\n",
    "    parsed = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'videos', 'sentences'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>sen_id</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a cartoon animals runs through an ice cave in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>video2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a cartoon character runs around inside of a vi...</td>\n",
       "      <td>1</td>\n",
       "      <td>video2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a character is running in the snow</td>\n",
       "      <td>2</td>\n",
       "      <td>video2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a person plays a video game centered around ic...</td>\n",
       "      <td>3</td>\n",
       "      <td>video2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a person plays online and records themselves</td>\n",
       "      <td>4</td>\n",
       "      <td>video2960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption  sen_id   video_id\n",
       "0  a cartoon animals runs through an ice cave in ...       0  video2960\n",
       "1  a cartoon character runs around inside of a vi...       1  video2960\n",
       "2                 a character is running in the snow       2  video2960\n",
       "3  a person plays a video game centered around ic...       3  video2960\n",
       "4       a person plays online and records themselves       4  video2960"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(parsed.keys())\n",
    "data = pd.DataFrame(parsed['sentences'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_caption_dict()->tuple:\n",
    "    '''\n",
    "    Creates two dictionaries: \n",
    "    1.) caption_dict with key as video_id and value as list of captions for that video.\n",
    "    {video_id:[caption_1, caption_2, caption_3 ....], ..}   \n",
    "    2.) sentence_ids which has video_id as the key and list of sentence_ids as value. \n",
    "    sen_ids are ids attached with each caption.\n",
    "    '''\n",
    "    captions_dict = {}\n",
    "    sentence_ids = {} \n",
    "\n",
    "    for video_id in list(data['video_id'].unique()):\n",
    "\n",
    "        caption_list = list(data[data['video_id'] == video_id].caption)\n",
    "        sentence_list = list(data[data['video_id'] == video_id].sen_id)\n",
    "        captions_dict[video_id] = caption_list\n",
    "        sentence_ids[video_id] = sentence_list\n",
    "        \n",
    "    return captions_dict, sentence_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('captions_dict.pickle', 'rb') as handle:\n",
    "    captions_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_dict = create_caption_dict()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('captions_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(captions_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_text(captions_dict:dict)->list:\n",
    "    '''Returns all the captions from all the videos as a list'''\n",
    "    \n",
    "    caption_text = []\n",
    "    for k, v in captions_dict.items():\n",
    "        for caption in v:\n",
    "            caption = ''.join([ch for ch in caption if ch not in punctuation])\n",
    "            caption  = '<sos> ' + caption + ' <eos>'\n",
    "            caption_text.append(caption)\n",
    "    \n",
    "    return caption_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_text = gather_text(captions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> a cartoon animals runs through an ice cave in a video game <eos>',\n",
       " '<sos> a cartoon character runs around inside of a video game <eos>',\n",
       " '<sos> a character is running in the snow <eos>',\n",
       " '<sos> a person plays a video game centered around ice age the movie <eos>',\n",
       " '<sos> a person plays online and records themselves <eos>',\n",
       " '<sos> a scene from the ice age video game is shown <eos>',\n",
       " '<sos> a video game character is jumping about in a cave <eos>',\n",
       " '<sos> a video game of a little animal running through an ice tunnel <eos>',\n",
       " '<sos> a video game of a small animal <eos>',\n",
       " '<sos> a video shows gameplay from ice age <eos>']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_text[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(caption_text:list)->tuple:\n",
    "    '''\n",
    "    Creates a vocabulary from the text dataset. Returns vocab_to_int which maps each word\n",
    "    to an integer and vice-versa.\n",
    "    '''\n",
    "    words = []\n",
    "    for text in caption_text:\n",
    "        for word in text.split():\n",
    "            words.append(word)\n",
    "    \n",
    "    counts = Counter(words)\n",
    "    vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "    #vocab['<sos>'], vocab['<eos>'] = -1, -2\n",
    "    vocab_to_int = {word:i for i, word in enumerate(vocab, 1)}\n",
    "    int_to_vocab = {v:k for k,v in vocab_to_int.items()}\n",
    "    \n",
    "    return vocab, vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, vocab_to_int, int_to_vocab = create_vocab(caption_text)\n",
    "#vocab_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_to_int(caption_text:list, vocab_to_int:dict)->list:\n",
    "    '''\n",
    "    Numericalizes the captions by referring to the mapping dictionary.\n",
    "    '''\n",
    "    captions_to_int = []\n",
    "    for i, caption in enumerate(caption_text):\n",
    "        ids = []\n",
    "        words = caption.split()\n",
    "\n",
    "        for word in words:\n",
    "\n",
    "            ids.append(vocab_to_int[word])\n",
    "\n",
    "        captions_to_int.append(ids)\n",
    "    \n",
    "    return captions_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 20\n",
    "def pad_sequences()->list:\n",
    "    '''\n",
    "    Pads sequences/captions with 0's if their length is less than seq_len else truncates\n",
    "    them to seq_len.\n",
    "    '''\n",
    "    padded_captions = []\n",
    "    for ids in captions_to_int:\n",
    "        ids = np.array(ids)\n",
    "        if len(ids) > 20:\n",
    "            ids = ids[:20]\n",
    "        else:\n",
    "            ids = np.pad(ids,(seq_len-len(ids),0),'constant')\n",
    "\n",
    "        padded_captions.append(list(ids))\n",
    "    \n",
    "    return padded_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_to_int = caption_to_int(caption_text,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#captions_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab_to_int.pickle', 'wb') as handle:\n",
    "    pickle.dump(vocab_to_int, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Video(object):\n",
    "    \n",
    "    def __init__(self, video_id, captions=[], sentence_ids=[]):\n",
    "        self.video_id = video_id\n",
    "        self.captions = captions\n",
    "        self.sentence_ids = sentence_ids\n",
    "        \n",
    "    def captions_to_token(self, vocab_to_int):\n",
    "        \n",
    "        self.caption_tokens = []\n",
    "        for caption in self.captions:\n",
    "            ids = []\n",
    "            words = caption.split()\n",
    "            for word in words:\n",
    "                ids.append(vocab_to_int[word])\n",
    "\n",
    "            self.caption_tokens.append(ids)\n",
    "        \n",
    "        #return self.caption_tokens\n",
    "    \n",
    "    \n",
    "    def pad_captions(self, seq_len):\n",
    "        \n",
    "        self.padded_captions = []\n",
    "        for ids in self.caption_tokens:\n",
    "            ids = np.array(ids)\n",
    "            if len(ids) > seq_len:\n",
    "                ids = ids[:seq_len]\n",
    "            else:\n",
    "                ids = np.pad(ids,(0,seq_len-len(ids)),'constant')\n",
    "\n",
    "            self.padded_captions.append(list(ids))\n",
    "        \n",
    "        #return self.padded_captions\n",
    "\n",
    "    \n",
    "    def calculate_output_captions(self):\n",
    "        \n",
    "        self.output_captions = []\n",
    "        \n",
    "        for ids in self.padded_captions:\n",
    "            ids = ids[1:]\n",
    "            ids.append(0)\n",
    "            \n",
    "            self.output_captions.append(ids)\n",
    "        \n",
    "        return self.output_captions\n",
    "    \n",
    "    def get_video_frames(self, transform):\n",
    "        \n",
    "        frame_features = []\n",
    "        path = './frames/'+self.video_id+'/'\n",
    "        #frames = os.listdir(path)\n",
    "        for frame in os.listdir(path):\n",
    "            img = Image.open(path+frame)\n",
    "            img = transform(img)\n",
    "            frame_features.append(img)\n",
    "        \n",
    "        if len(frame_features) < 32:\n",
    "            pad_val = 32 - len(frame_features)\n",
    "            pad = torch.zeros(pad_val, 3, 224, 224)\n",
    "            self.frames = torch.cat([torch.stack(frame_features, dim=0), pad], dim=0)\n",
    "        else:\n",
    "            self.frames = torch.stack(frame_features,dim=0)\n",
    "        \n",
    "        #return self.frames\n",
    "        \n",
    "    \n",
    "    def get_vgg_tensor(self, transforms, model):\n",
    "    \n",
    "        vgg_features = []\n",
    "        path = './frames/'+self.video_id+'/'\n",
    "        frames = os.listdir(path)\n",
    "        for frame in frames:\n",
    "            img = Image.open(path+frame)\n",
    "            img = transforms(img)\n",
    "\n",
    "            #features = model(img.unsqueeze(0))\n",
    "\n",
    "            vgg_features.append(img)\n",
    "\n",
    "        feats = torch.stack(vgg_features, dim=0)\n",
    "        feats = feats.cuda()\n",
    "        model = model.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.vgg_tensor = model(feats)\n",
    "\n",
    "        del feats\n",
    "        gc.collect()\n",
    "        model = model.cpu()\n",
    "        self.vgg_tensor = vgg_tensor.cpu()\n",
    "\n",
    "        return self.vgg_tensor\n",
    "\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}'.format(self.video_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    #vgg = models.vgg16(pretrained=True)\n",
    "    #vgg.classifier = nn.Sequential(*[vgg.classifier[i] for i in range(4)])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "transform = get_transforms()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_tensor(video_id, transforms, model):\n",
    "    \n",
    "    vgg_features = []\n",
    "    path = './frames/'+video_id+'/'\n",
    "    frames = os.listdir(path)\n",
    "    for frame in frames:\n",
    "        img = Image.open(path+frame)\n",
    "        img = transforms(img)\n",
    "        \n",
    "        #features = model(img.unsqueeze(0))\n",
    "        \n",
    "        vgg_features.append(img)\n",
    "    \n",
    "    feats = torch.stack(vgg_features, dim=0)\n",
    "    feats = feats.cuda()\n",
    "    model = model.cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        vgg_tensor = model(feats)\n",
    "    \n",
    "    del feats\n",
    "    gc.collect()\n",
    "    model = model.cpu()\n",
    "    vgg_tensor = vgg_tensor.cpu()\n",
    "\n",
    "    return vgg_tensor\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_caption(captions:list):\n",
    "    \n",
    "    clean_captions = []\n",
    "    for caption in captions:\n",
    "        caption = ''.join([ch for ch in caption if ch not in punctuation])\n",
    "        caption  = '<sos> ' + caption + ' <eos>'\n",
    "        clean_captions.append(caption)\n",
    "    \n",
    "    return clean_captions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_objects(num_objects)->list:\n",
    "    '''Creates video objects with all the properties and methods.'''\n",
    "    \n",
    "    video_objects = [None] * num_objects\n",
    "    for i in range(len(video_objects)):\n",
    "\n",
    "        video_id = 'video'+str(i)\n",
    "        captions = list(data[data['video_id'] == video_id].caption)\n",
    "        captions = clean_caption(captions)\n",
    "        sentence_ids = list(data[data['video_id'] == video_id].sen_id)\n",
    "\n",
    "        video_objects[i] = Video(video_id=video_id, captions=captions,sentence_ids=sentence_ids)\n",
    "    \n",
    "    return video_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_objects = create_video_objects(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('video_objects.pickle', 'wb') as handle:\n",
    "    pickle.dump(video_objects, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, video_objects, vocab_to_int, transform):\n",
    "        self.video_objects = video_objects\n",
    "        self.call_funcs(vocab_to_int, transform)\n",
    "        \n",
    "    def call_funcs(self, vocab_to_int, transform):\n",
    "        \n",
    "        for video in self.video_objects:\n",
    "            video.captions_to_token(vocab_to_int)\n",
    "            video.pad_captions(20)\n",
    "            video.get_video_frames(transform)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(video_objects)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return video_objects[index].frames, torch.tensor(video_objects[index].padded_captions) \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_data = VideoDataset(video_objects, vocab_to_int, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(vid_data, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dl64.pickle', 'wb') as handle:\n",
    "    pickle.dump(dl, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(64):\n",
    "    l.append(vid_data[i][0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 3, 224, 224])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 20, 20])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    1,   25,    4,   46,    3,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,   45,    4,   55,    3,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,    7,  289,    1,  246,  109,    5, 3772,    3,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,    7,  289,   59,    5,  120,    6,   19, 2841,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,    7,   88,    1,   25,    3,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,    7,    4,   88,    1,   25,    3,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,    7,    4,   88,   59,    1,  120,    3,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,    7,    4,   88,    6,    1,   25,   71,  449,    9,    1,\n",
       "          332,    3,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,    7,    4,   88,    3,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,    7,  165,    5,   25, 6976,    6,    1, 1785,  120,    3,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,    7,   38,    5,  161,  295,    9,    1,   25,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,    7, 7626,  592,   28,  828,   88,   19, 2841,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,   18,    4,   88,   28,   25,   67, 4423,    6,    5,  120,\n",
       "            3,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,   18,  266,   15,    1,   25,    3,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,   58,   88,    1,   25,   59,    5,  120,    3,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    7,   16,   15,    1,   25,   32,   88,    3,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    5,    7,  289,    5,   25,    3,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    5,    7,   88,    5, 2841,   71, 4101,   71, 3217,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,    7,    4,   88,    3,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,   58,   88,    1,   25,   59,    5,  120,    3,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1][0] # 20 captions for 0th video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = x[1].permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 20, 16])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 16])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp[0].shape #seqlen, bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  1, 25,  4, 46,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], dtype=torch.int32)\n",
      "tensor([ 2,  1, 45,  4, 55,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], dtype=torch.int32)\n",
      "tensor([   2,    1,    7,  289,    1,  246,  109,    5, 3772,    3,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0], dtype=torch.int32)\n",
      "tensor([   2,    1,    7,  289,   59,    5,  120,    6,   19, 2841,    3,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0], dtype=torch.int32)\n",
      "tensor([ 2,  1,  7, 88,  1, 25,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], dtype=torch.int32)\n",
      "tensor([ 2,  1,  7,  4, 88,  1, 25,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], dtype=torch.int32)\n",
      "tensor([  2,   1,   7,   4,  88,  59,   1, 120,   3,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0], dtype=torch.int32)\n",
      "tensor([  2,   1,   7,   4,  88,   6,   1,  25,  71, 449,   9,   1, 332,   3,\n",
      "          0,   0,   0,   0,   0,   0], dtype=torch.int32)\n",
      "tensor([ 2,  1,  7,  4, 88,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], dtype=torch.int32)\n",
      "tensor([   2,    1,    7,  165,    5,   25, 6976,    6,    1, 1785,  120,    3,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0], dtype=torch.int32)\n",
      "tensor([  2,   1,   7,  38,   5, 161, 295,   9,   1,  25,   3,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0], dtype=torch.int32)\n",
      "tensor([   2,    1,    7, 7626,  592,   28,  828,   88,   19, 2841,    3,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0], dtype=torch.int32)\n",
      "tensor([   2,    1,   18,    4,   88,   28,   25,   67, 4423,    6,    5,  120,\n",
      "           3,    0,    0,    0,    0,    0,    0,    0], dtype=torch.int32)\n",
      "tensor([  2,   1,  18, 266,  15,   1,  25,   3,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0], dtype=torch.int32)\n",
      "tensor([  2,  58,  88,   1,  25,  59,   5, 120,   3,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0], dtype=torch.int32)\n",
      "tensor([ 2,  7, 16, 15,  1, 25, 32, 88,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], dtype=torch.int32)\n",
      "tensor([  2,   5,   7, 289,   5,  25,   3,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0], dtype=torch.int32)\n",
      "tensor([   2,    5,    7,   88,    5, 2841,   71, 4101,   71, 3217,    3,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0], dtype=torch.int32)\n",
      "tensor([ 2,  1,  7,  4, 88,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], dtype=torch.int32)\n",
      "tensor([  2,  58,  88,   1,  25,  59,   5, 120,   3,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(xp[i][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2],\n",
       "        [    1,     6,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,  1665],\n",
       "        [   25,     1, 10453,   257,    24,   338,   175,     7,   952,     7,\n",
       "             7,   400,     7,  1292,   312,    13],\n",
       "        [    4,    92,    38,   383,    65,     4,     8,  1178,    58,   214,\n",
       "           393,   197,     4,     7,    27,  2010],\n",
       "        [   46,     1,     1,     4,     1,    20,     1,    10,    44,   942,\n",
       "            23,     9,  2936,  2929,     1,    10],\n",
       "        [    3,    12,  1402,    40,    43,    14,   368,     1,     8,  1442,\n",
       "           391,     5,    16,    14,   971,   211],\n",
       "        [    0,   485,     3,  2796,    70,     1,    13,   175, 17017,    10,\n",
       "             3,  4326,    11,  3713,    54,     9],\n",
       "        [    0,    84,     0,     6,     3,   959,    20,   215,     6,     1,\n",
       "             0,     3,    76,  3058,     3,    76],\n",
       "        [    0,   180,     0,     1,     0,   177,     3,   150,     1,    72,\n",
       "             0,     0,     7,     3,     0,    10],\n",
       "        [    0,    62,     0,    17,     0,     3,     0,    57,   306,  2280,\n",
       "             0,     0,     3,     0,     0,     5],\n",
       "        [    0,     5,     0,    22,     0,     0,     0,     3,     3,     3,\n",
       "             0,     0,     0,     0,     0,   121],\n",
       "        [    0,   248,     0,     3,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,    66],\n",
       "        [    0,     8,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     3],\n",
       "        [    0,   927,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [    0,    42,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [    0,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf = x[0].permute(1,0,2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 3, 224, 224])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
