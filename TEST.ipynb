{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocess'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-903dd535cc88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_json\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_caption_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_video_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean_caption\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgather_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_transforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVideo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVideoDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_caption_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEncoderBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDecoderBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeq2SeqBase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'preprocess'"
     ]
    }
   ],
   "source": [
    "from preprocess import read_json, create_caption_dict, create_video_objects, clean_caption, gather_text, get_transforms\n",
    "from preprocess import Video, VideoDataset, create_vocab, get_caption_dict\n",
    "from base import EncoderBase, DecoderBase, Seq2SeqBase\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import random\n",
    "from preprocess import *\n",
    "from base import *\n",
    "from gru_summ_model import SummarizationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_dict = get_caption_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_text = gather_text(captions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, vocab_to_int, int_to_vocab = create_vocab(caption_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_objects = create_video_objects(0, 16, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = VideoDataset(train_video_objects, vocab_to_int, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_video_objects = create_video_objects(20, 36, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = VideoDataset(valid_video_objects, vocab_to_int, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(valid_data, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 1024\n",
    "OUTPUT_DIM = len(vocab) #len(vocab) #import vocab here\n",
    "ENCODER_HID_DIM = 512\n",
    "DECODER_HID_DIM = 512\n",
    "EMBEDDING_DIM = 256\n",
    "DROPOUT = 0.4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderBase(hidden_dim=ENCODER_HID_DIM, input_dim=INPUT_DIM, device=device)\n",
    "decoder = DecoderBase(EMBEDDING_DIM, DECODER_HID_DIM, OUTPUT_DIM, DROPOUT)\n",
    "\n",
    "\n",
    "\n",
    "model = Seq2SeqBase(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqBase(\n",
       "  (encoder): EncoderBase(\n",
       "    (gru): GRU(1024, 512, batch_first=True)\n",
       "  )\n",
       "  (decoder): DecoderBase(\n",
       "    (embedding): Embedding(28790, 256)\n",
       "    (gru): GRU(256, 512)\n",
       "    (linear): Linear(in_features=512, out_features=28790, bias=True)\n",
       "    (dropout): Dropout(p=0.4, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)\n",
    "\n",
    "def get_opt_loss():\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    \n",
    "    return optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    parameters_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return parameters_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 25,684,598 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, opt, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for frames, captions in loader:\n",
    "        \n",
    "        # frames = [bs, seq_len, 3, 224, 224] = [bs, 32, 3, 224, 224]\n",
    "        # captions = [bs, num_captions, seq_len] = [bs, 20, 20]\n",
    "        \n",
    "        #captions = captions.permute(1, 2, 0).type(torch.LongTensor)\n",
    "         # captions = [num_captions, seq_len, bs] = [20, 20, bs]\n",
    "        \n",
    "        frames = frames.to(device)\n",
    "        captions = captions.to(device)\n",
    "       \n",
    "        \n",
    "        for i in range(captions.shape[1]):\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            \n",
    "            output = model(frames, captions[:,i,:].long())\n",
    "            print('output1: ', output.shape)\n",
    "            # output [trg_len, bs, output_vocab_dim]\n",
    "            # captions[i] = [trg_len, bs]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg_len-1)*bs, output_dim]\n",
    "            print('output2: ', output.shape)\n",
    "            target = captions[:,i,:].T[1:].reshape(-1)\n",
    "            # target = [(trg_len-1)*bs]\n",
    "            print('target: ', target.shape)\n",
    "            loss = criterion(output, target.long())\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "            opt.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    \n",
    "    #print(epoch_loss/len(loader))\n",
    "    return epoch_loss / len(loader)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for frames, captions in loader:\n",
    "        \n",
    "        # frames = [bs, seq_len, 3, 224, 224] = [bs, 32, 3, 224, 224]\n",
    "        # captions = [bs, num_captions, seq_len] = [bs, 20, 20]\n",
    "        \n",
    "        #captions = captions.permute(1, 2, 0).type(torch.LongTensor)\n",
    "         # captions = [num_captions, seq_len, bs] = [20, 20, bs]\n",
    "        \n",
    "        frames = frames.to(device)\n",
    "        captions = captions.to(device)\n",
    "       \n",
    "        with torch.no_grad():\n",
    "            for i in range(captions.shape[1]):\n",
    "\n",
    "               \n",
    "\n",
    "                output = model(frames, captions[:,i,:].long())\n",
    "\n",
    "                # output [trg_len, bs, output_vocab_dim]\n",
    "                # captions[i] = [trg_len, bs]\n",
    "\n",
    "                output_dim = output.shape[-1]\n",
    "\n",
    "                output = output[1:].view(-1, output_dim)\n",
    "                # output = [(trg_len-1)*bs, output_dim]\n",
    "\n",
    "                target = captions[:,i,:].T[1:].reshape(-1)\n",
    "                # target = [(trg_len-1)*bs]\n",
    "\n",
    "                loss = criterion(output, target.long())\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "\n",
    "    #print(epoch_loss/len(loader))\n",
    "    return epoch_loss / len(loader)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n",
      "output1:  torch.Size([20, 4, 28790])\n",
      "output2:  torch.Size([76, 28790])\n",
      "target:  torch.Size([76])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-3c7503a32118>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-d86e25f259b6>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, loader, criterion)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[1;31m# output [trg_len, bs, output_vocab_dim]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\BE Captioning\\Code\\base.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src_frames, target, teacher_forcing_ratio)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;31m# [trg_len, bs, vocab_dim]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m# hidden [1, bs, hidden_dim]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\BE Captioning\\Code\\base.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;31m#             lenet_features = self.lenet_model(x)[:,:,-1,-1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mlenet_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cnn_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\BE Captioning\\Code\\base.py\u001b[0m in \u001b[0;36mget_cnn_features\u001b[1;34m(self, frames)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mcnn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgooglenet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mlenet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlenet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kushal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time, random\n",
    "N_EPOCHS = 1\n",
    "CLIP = 1\n",
    "optimizer, criterion = get_opt_loss()\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(20, 32, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 32, 100])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
